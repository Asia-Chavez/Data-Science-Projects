{"cells":[{"source":"<center><img src=\"car.jpg\" width=500></center>\n\n\nInsurance companies invest a lot of time and money into optimizing their pricing and accurately estimating the likelihood that customers will make a claim. In many countries insurance it is a legal requirement to have car insurance in order to drive a vehicle on public roads, so the market is very large!\n\n(`Source: https://www.accenture.com/_acnmedia/pdf-84/accenture-machine-leaning-insurance.pdf`) \n\nKnowing all of this, On the Road car insurance have requested your services in building a model to predict whether a customer will make a claim on their insurance during the policy period. As they have very little expertise and infrastructure for deploying and monitoring machine learning models, they've asked you to identify the single feature that results in the best performing model, as measured by accuracy, so they can start with a simple model in production.\n\nThey have supplied you with their customer data as a csv file called `car_insurance.csv`, along with a table detailing the column names and descriptions below.","metadata":{},"id":"c3f0e974-faf8-458f-bf2a-06a469d0ea5e","cell_type":"markdown","attachments":{}},{"source":"\n\n## The dataset\n\n| Column | Description |\n|--------|-------------|\n| `id` | Unique client identifier |\n| `age` | Client's age: <br> <ul><li>`0`: 16-25</li><li>`1`: 26-39</li><li>`2`: 40-64</li><li>`3`: 65+</li></ul> |\n| `gender` | Client's gender: <br> <ul><li>`0`: Female</li><li>`1`: Male</li></ul> |\n| `driving_experience` | Years the client has been driving: <br> <ul><li>`0`: 0-9</li><li>`1`: 10-19</li><li>`2`: 20-29</li><li>`3`: 30+</li></ul> |\n| `education` | Client's level of education: <br> <ul><li>`0`: No education</li><li>`1`: High school</li><li>`2`: University</li></ul> |\n| `income` | Client's income level: <br> <ul><li>`0`: Poverty</li><li>`1`: Working class</li><li>`2`: Middle class</li><li>`3`: Upper class</li></ul> |\n| `credit_score` | Client's credit score (between zero and one) |\n| `vehicle_ownership` | Client's vehicle ownership status: <br><ul><li>`0`: Does not own their vehilce (paying off finance)</li><li>`1`: Owns their vehicle</li></ul> |\n| `vehcile_year` | Year of vehicle registration: <br><ul><li>`0`: Before 2015</li><li>`1`: 2015 or later</li></ul> |\n| `married` | Client's marital status: <br><ul><li>`0`: Not married</li><li>`1`: Married</li></ul> |\n| `children` | Client's number of children |\n| `postal_code` | Client's postal code | \n| `annual_mileage` | Number of miles driven by the client each year |\n| `vehicle_type` | Type of car: <br> <ul><li>`0`: Sedan</li><li>`1`: Sports car</li></ul> |\n| `speeding_violations` | Total number of speeding violations received by the client | \n| `duis` | Number of times the client has been caught driving under the influence of alcohol |\n| `past_accidents` | Total number of previous accidents the client has been involved in |\n| `outcome` | Whether the client made a claim on their car insurance (response variable): <br><ul><li>`0`: No claim</li><li>`1`: Made a claim</li></ul> |","metadata":{},"id":"8928ffdf-25d6-4ad9-909f-0dd8d10b9a42","cell_type":"markdown"},{"source":"# https://projects.datacamp.com/projects/1645\n\n# Import required modules\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas.api.types import is_numeric_dtype\nfrom sklearn.metrics import (\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    confusion_matrix,\n    classification_report\n)\n\n# Import CSV Data\ndf = pd.read_csv('car_insurance.csv')\n\n# Review Data\n# df.info() # Get a summary of the DataFrame, including data types and non-null values\n# df.head() # View the first few rows of the DataFrame\n# df.describe() # Get descriptive statistics for numerical columns\n\n# -- Check for Imbalanced Data\nclass_counts = df['outcome'].value_counts()\nclass_proportions = df['outcome'].value_counts(normalize=True) * 100\n# print(\"Class Counts:\\n\", class_counts)\n# print(\"\\nClass Proportions (%):\\n\", class_proportions)\n# plt.figure(figsize=(8, 6))\n# sns.countplot(x='outcome', data=df)\n# plt.title('Distribution of Outcome Classes')\n# plt.xlabel('Class')\n# plt.ylabel('Count')\n# plt.show()\n\n# -- Plot Data\n# for col in df.columns:\n#     if is_numeric_dtype(df[col]):\n#         plt.hist(df[[col]])\n#         plt.xlabel(col)\n#         plt.ylabel(\"Frequency\")\n#         plt.show()\n\n\n# -- Objects: driving_experience, education, income, vehicle_year, vehicle_type\n# -- Missing Data: credit_score, anual_mileage\n\n# Clean / Transform Data\n# -- Convert Objects to Numbers\n# -- Convert object type to a categorical type\ndf['driving_experience'] = df['driving_experience'].astype('category')\ndf['education'] = df['education'].astype('category')\ndf['income'] = df['income'].astype('category')\ndf['vehicle_year'] = df['vehicle_year'].astype('category')\ndf['vehicle_type'] = df['vehicle_type'].astype('category')\n# -- Convert the categorical column to numerical codes\ndf['driving_experience'] = df['driving_experience'].cat.codes\ndf['education'] = df['education'].cat.codes\ndf['income'] = df['income'].cat.codes\ndf['vehicle_year'] = df['vehicle_year'].cat.codes\ndf['vehicle_type'] = df['vehicle_type'].cat.codes\n\n# -- Fill missing values with a specific value (e.g., mean, median, or a constant)\ndf['credit_score'].fillna(df['credit_score'].mean(), inplace=True)\ndf['annual_mileage'].fillna(df['annual_mileage'].mean(), inplace=True)\n\n# -- Handle Duplicates (None)\n# df.drop_duplicates(inplace=True)\n\n# -- Review Data\n# df.info() # Get a summary of the DataFrame, including data types and non-null values\n# df.head() # View the first few rows of the DataFrame\n# df.describe() # Get descriptive statistics for numerical columns\n\n# -- Plot Data\n# for col in df.columns:\n#     plt.hist(df[[col]])\n#     plt.xlabel(col)\n#     plt.ylabel(\"Frequency\")\n#     plt.show()\n\n# Identify best feature, as measured by accuracy\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom collections import Counter\n\ndef find_best_feature(df, model, scale=False, target='outcome', show_confusion=True):\n\n    feature_metrics = []\n\n    # Reuse the same train/test split for fairness across features\n    X_full = df.drop(columns=[target,'id'])\n    y = df[target]\n    # print(\"Original class distribution:\", Counter(y))\n    \n    # Undersampling using RandomUnderSampler\n    undersample = RandomUnderSampler(sampling_strategy='majority')\n    X_full, y = undersample.fit_resample(X_full, y)\n    # print(\"Undersampled class distribution:\", Counter(y))\n\n    # # Oversampling using RandomOverSampler - Yields Same Overall Results as Undersample\n    # oversample = RandomOverSampler(sampling_strategy='minority')\n    # X_full, y = oversample.fit_resample(X_full, y)\n    # print(\"Oversampled class distribution:\", Counter(y))\n    \n    X_train_full, X_test_full, y_train, y_test = train_test_split(\n        X_full, y, test_size=0.2, random_state=42)\n\n    for col in X_full.columns:\n        X_train = X_train_full[[col]].copy()\n        X_test = X_test_full[[col]].copy()\n\n        # Optional scaling\n        if scale:\n            scaler = StandardScaler()\n            X_train = scaler.fit_transform(X_train)\n            X_test = scaler.transform(X_test)\n\n        # Train model\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n\n        # Collect metrics\n        acc = accuracy_score(y_test, y_pred)\n        prec = precision_score(y_test, y_pred, zero_division=0)\n        rec = recall_score(y_test, y_pred, zero_division=0)\n        f1 = f1_score(y_test, y_pred, zero_division=0)\n        unique_preds = np.unique(y_pred, return_counts=True)\n\n        feature_metrics.append({\n            'Feature': col,\n            'Accuracy': acc,\n            'Precision': prec,\n            'Recall': rec,\n            'F1': f1,\n            'Predicted_Classes': dict(zip(unique_preds[0], unique_preds[1]))\n        })\n\n    # Convert to DataFrame for readability\n    results = pd.DataFrame(feature_metrics).sort_values(by='Accuracy', ascending=False)\n    best_feature = results.iloc[0]['Feature']\n    best_acc = results.iloc[0]['Accuracy']\n\n    print(f\"\\n Best Feature: {best_feature} (Accuracy: {best_acc:.4f})\")\n    print(\"\\n Summary of All Features:\\n\")\n    display(results)\n\n    # Optional confusion matrix for best feature\n    if show_confusion:\n        print(f\"\\nüîç Confusion Matrix for Best Feature: {best_feature}\")\n        X_train = X_train_full[[best_feature]]\n        X_test = X_test_full[[best_feature]]\n\n        if scale:\n            scaler = StandardScaler()\n            X_train = scaler.fit_transform(X_train)\n            X_test = scaler.transform(X_test)\n\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n\n        cm = confusion_matrix(y_test, y_pred)\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n        plt.xlabel('Predicted')\n        plt.ylabel('Actual')\n        plt.title(f'Confusion Matrix ‚Äì {best_feature}')\n        plt.show()\n\n        print(\"\\nClassification Report:\")\n        print(classification_report(y_test, y_pred, zero_division=0))\n\n\n# -- LogisticRegression\nprint(\"Logisitic Regression\")\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(solver='liblinear', random_state=42)      \nfind_best_feature(df, model, scale=False, target='outcome', show_confusion=False)\n\n# -- DecisionTreeClassifier\nprint(\"Decision Tree Classifier\")\nfrom sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier(criterion='gini', max_depth=10)\nfind_best_feature(df, model, scale=False, target='outcome', show_confusion=False)\n\n# -- RandomForestClassifier\nprint(\"Random Forest Classifier\")\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nfind_best_feature(df, model, scale=False, target='outcome', show_confusion=False)\n\n# -- Standard Vector Machine\nprint(\"Standard Vector Machine Classifier\")\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nmodel = SVC(kernel='linear', C=1.0, random_state=42) # Linear kernel for binary class\nfind_best_feature(df, model, scale=True, target='outcome', show_confusion=False)\n\n# Results\n# -- Original class distribution: Counter({0.0: 6867, 1.0: 3133})\n# -- Undersampled class distribution: Counter({0.0: 3133, 1.0: 3133})\n# -- LogisticRegression: driving_experience (Accuracy: 0.7560)\n# -- DecisionTreeClassifier: driving_experience (Accuracy: 0.7616)\n# -- RandomForestClassifier: driving_experience (Accuracy: 0.7544)\n# -- Standard Vector Machine: driving_experience (Accuracy: 0.7671)\n","metadata":{"executionTime":9746,"id":"bA5ajAmk7XH6","lastSuccessfullyExecutedCode":"# https://projects.datacamp.com/projects/1645\n\n# Import required modules\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas.api.types import is_numeric_dtype\nfrom sklearn.metrics import (\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    confusion_matrix,\n    classification_report\n)\n\n# Import CSV Data\ndf = pd.read_csv('car_insurance.csv')\n\n# Review Data\n# df.info() # Get a summary of the DataFrame, including data types and non-null values\n# df.head() # View the first few rows of the DataFrame\n# df.describe() # Get descriptive statistics for numerical columns\n\n# -- Check for Imbalanced Data\nclass_counts = df['outcome'].value_counts()\nclass_proportions = df['outcome'].value_counts(normalize=True) * 100\n# print(\"Class Counts:\\n\", class_counts)\n# print(\"\\nClass Proportions (%):\\n\", class_proportions)\n# plt.figure(figsize=(8, 6))\n# sns.countplot(x='outcome', data=df)\n# plt.title('Distribution of Outcome Classes')\n# plt.xlabel('Class')\n# plt.ylabel('Count')\n# plt.show()\n\n# -- Plot Data\n# for col in df.columns:\n#     if is_numeric_dtype(df[col]):\n#         plt.hist(df[[col]])\n#         plt.xlabel(col)\n#         plt.ylabel(\"Frequency\")\n#         plt.show()\n\n\n# -- Objects: driving_experience, education, income, vehicle_year, vehicle_type\n# -- Missing Data: credit_score, anual_mileage\n\n# Clean / Transform Data\n# -- Convert Objects to Numbers\n# -- Convert object type to a categorical type\ndf['driving_experience'] = df['driving_experience'].astype('category')\ndf['education'] = df['education'].astype('category')\ndf['income'] = df['income'].astype('category')\ndf['vehicle_year'] = df['vehicle_year'].astype('category')\ndf['vehicle_type'] = df['vehicle_type'].astype('category')\n# -- Convert the categorical column to numerical codes\ndf['driving_experience'] = df['driving_experience'].cat.codes\ndf['education'] = df['education'].cat.codes\ndf['income'] = df['income'].cat.codes\ndf['vehicle_year'] = df['vehicle_year'].cat.codes\ndf['vehicle_type'] = df['vehicle_type'].cat.codes\n\n# -- Fill missing values with a specific value (e.g., mean, median, or a constant)\ndf['credit_score'].fillna(df['credit_score'].mean(), inplace=True)\ndf['annual_mileage'].fillna(df['annual_mileage'].mean(), inplace=True)\n\n# -- Handle Duplicates (None)\n# df.drop_duplicates(inplace=True)\n\n# -- Review Data\n# df.info() # Get a summary of the DataFrame, including data types and non-null values\n# df.head() # View the first few rows of the DataFrame\n# df.describe() # Get descriptive statistics for numerical columns\n\n# -- Plot Data\n# for col in df.columns:\n#     plt.hist(df[[col]])\n#     plt.xlabel(col)\n#     plt.ylabel(\"Frequency\")\n#     plt.show()\n\n# Identify best feature, as measured by accuracy\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom collections import Counter\n\ndef find_best_feature(df, model, scale=False, target='outcome', show_confusion=True):\n\n    feature_metrics = []\n\n    # Reuse the same train/test split for fairness across features\n    X_full = df.drop(columns=[target,'id'])\n    y = df[target]\n    # print(\"Original class distribution:\", Counter(y))\n    \n    # Undersampling using RandomUnderSampler\n    undersample = RandomUnderSampler(sampling_strategy='majority')\n    X_full, y = undersample.fit_resample(X_full, y)\n    # print(\"Undersampled class distribution:\", Counter(y))\n\n    # # Oversampling using RandomOverSampler - Yields Same Overall Results as Undersample\n    # oversample = RandomOverSampler(sampling_strategy='minority')\n    # X_full, y = oversample.fit_resample(X_full, y)\n    # print(\"Oversampled class distribution:\", Counter(y))\n    \n    X_train_full, X_test_full, y_train, y_test = train_test_split(\n        X_full, y, test_size=0.2, random_state=42)\n\n    for col in X_full.columns:\n        X_train = X_train_full[[col]].copy()\n        X_test = X_test_full[[col]].copy()\n\n        # Optional scaling\n        if scale:\n            scaler = StandardScaler()\n            X_train = scaler.fit_transform(X_train)\n            X_test = scaler.transform(X_test)\n\n        # Train model\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n\n        # Collect metrics\n        acc = accuracy_score(y_test, y_pred)\n        prec = precision_score(y_test, y_pred, zero_division=0)\n        rec = recall_score(y_test, y_pred, zero_division=0)\n        f1 = f1_score(y_test, y_pred, zero_division=0)\n        unique_preds = np.unique(y_pred, return_counts=True)\n\n        feature_metrics.append({\n            'Feature': col,\n            'Accuracy': acc,\n            'Precision': prec,\n            'Recall': rec,\n            'F1': f1,\n            'Predicted_Classes': dict(zip(unique_preds[0], unique_preds[1]))\n        })\n\n    # Convert to DataFrame for readability\n    results = pd.DataFrame(feature_metrics).sort_values(by='Accuracy', ascending=False)\n    best_feature = results.iloc[0]['Feature']\n    best_acc = results.iloc[0]['Accuracy']\n\n    print(f\"\\n Best Feature: {best_feature} (Accuracy: {best_acc:.4f})\")\n    print(\"\\n Summary of All Features:\\n\")\n    display(results)\n\n    # Optional confusion matrix for best feature\n    if show_confusion:\n        print(f\"\\nüîç Confusion Matrix for Best Feature: {best_feature}\")\n        X_train = X_train_full[[best_feature]]\n        X_test = X_test_full[[best_feature]]\n\n        if scale:\n            scaler = StandardScaler()\n            X_train = scaler.fit_transform(X_train)\n            X_test = scaler.transform(X_test)\n\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n\n        cm = confusion_matrix(y_test, y_pred)\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n        plt.xlabel('Predicted')\n        plt.ylabel('Actual')\n        plt.title(f'Confusion Matrix ‚Äì {best_feature}')\n        plt.show()\n\n        print(\"\\nClassification Report:\")\n        print(classification_report(y_test, y_pred, zero_division=0))\n\n    #return results\n\n\n# -- LogisticRegression\nprint(\"Logisitic Regression\")\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(solver='liblinear', random_state=42)      \nfind_best_feature(df, model, scale=False, target='outcome', show_confusion=False)\n\n# -- DecisionTreeClassifier\nprint(\"Decision Tree Classifier\")\nfrom sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier(criterion='gini', max_depth=10)\nfind_best_feature(df, model, scale=False, target='outcome', show_confusion=False)\n\n# -- RandomForestClassifier\nprint(\"Random Forest Classifier\")\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nfind_best_feature(df, model, scale=False, target='outcome', show_confusion=False)\n\n# -- Standard Vector Machine\nprint(\"Standard Vector Machine Classifier\")\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nmodel = SVC(kernel='linear', C=1.0, random_state=42) # Linear kernel for binary class\nfind_best_feature(df, model, scale=True, target='outcome', show_confusion=False)\n\n# Results\n# -- Original class distribution: Counter({0.0: 6867, 1.0: 3133})\n# -- Undersampled class distribution: Counter({0.0: 3133, 1.0: 3133})\n# -- LogisticRegression: driving_experience (Accuracy: 0.7560)\n# -- DecisionTreeClassifier: driving_experience (Accuracy: 0.7616)\n# -- RandomForestClassifier: driving_experience (Accuracy: 0.7544)\n# -- Standard Vector Machine: driving_experience (Accuracy: 0.7671)\n","executionCancelledAt":null,"lastExecutedAt":1759696200912,"lastExecutedByKernel":"aedf7e86-8c98-4b3f-9bfc-43d64f104cc9","lastScheduledRunId":null,"outputsMetadata":{"0":{"height":143,"type":"stream"},"1":{"height":949,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"c3389399-3627-43a9-8659-7b359bbf13fb","nodeType":"const"}},"chartState":{"chartModel":{"modelType":"range","chartId":"id-wp8arycniae","chartType":"groupedColumn","chartThemeName":"datalabTheme","chartOptions":{"common":{"animation":{"enabled":true}}},"chartPalette":{"fills":["#6568A0","#43D7A4","#4095DB","#FACC5F","#CAE279","#F08083","#5BCDF2","#F099DC","#965858","#7DB64F","#A98954"],"strokes":["#6568A0","#43D7A4","#4095DB","#FACC5F","#CAE279","#F08083","#5BCDF2","#F099DC","#965858","#7DB64F","#A98954"],"up":{"fill":"#459d55","stroke":"#1e652e"},"down":{"fill":"#ef5452","stroke":"#a82529"},"neutral":{"fill":"#b5b5b5","stroke":"#575757"},"altUp":{"fill":"#5090dc","stroke":"#2b5c95"},"altDown":{"fill":"#ffa03a","stroke":"#cc6f10"},"altNeutral":{"fill":"#b5b5b5","stroke":"#575757"}},"cellRange":{"rowStartIndex":null,"rowStartPinned":null,"rowEndIndex":null,"rowEndPinned":null,"columns":[]},"switchCategorySeries":false,"suppressChartRanges":false,"unlinkChart":false,"version":"32.2.2"},"rangeChartModel":{"rangeColumns":[],"switchCategorySeries":false}}},"2":{"height":143,"type":"stream"},"3":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"0cf68a9e-328f-4cd7-8e9e-6b4f3b165389","nodeType":"const"}},"chartState":{"chartModel":{"modelType":"range","chartId":"id-0bbcn40uejab","chartType":"groupedColumn","chartThemeName":"datalabTheme","chartOptions":{"common":{"animation":{"enabled":true}}},"chartPalette":{"fills":["#6568A0","#43D7A4","#4095DB","#FACC5F","#CAE279","#F08083","#5BCDF2","#F099DC","#965858","#7DB64F","#A98954"],"strokes":["#6568A0","#43D7A4","#4095DB","#FACC5F","#CAE279","#F08083","#5BCDF2","#F099DC","#965858","#7DB64F","#A98954"],"up":{"fill":"#459d55","stroke":"#1e652e"},"down":{"fill":"#ef5452","stroke":"#a82529"},"neutral":{"fill":"#b5b5b5","stroke":"#575757"},"altUp":{"fill":"#5090dc","stroke":"#2b5c95"},"altDown":{"fill":"#ffa03a","stroke":"#cc6f10"},"altNeutral":{"fill":"#b5b5b5","stroke":"#575757"}},"cellRange":{"rowStartIndex":null,"rowStartPinned":null,"rowEndIndex":null,"rowEndPinned":null,"columns":[]},"switchCategorySeries":false,"suppressChartRanges":false,"unlinkChart":false,"version":"32.2.2"},"rangeChartModel":{"rangeColumns":[],"switchCategorySeries":false}}},"4":{"height":143,"type":"stream"},"5":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"0cf68a9e-328f-4cd7-8e9e-6b4f3b165389","nodeType":"const"}},"chartState":{"chartModel":{"modelType":"range","chartId":"id-4heo6610qrp","chartType":"groupedColumn","chartThemeName":"datalabTheme","chartOptions":{"common":{"animation":{"enabled":true}}},"chartPalette":{"fills":["#6568A0","#43D7A4","#4095DB","#FACC5F","#CAE279","#F08083","#5BCDF2","#F099DC","#965858","#7DB64F","#A98954"],"strokes":["#6568A0","#43D7A4","#4095DB","#FACC5F","#CAE279","#F08083","#5BCDF2","#F099DC","#965858","#7DB64F","#A98954"],"up":{"fill":"#459d55","stroke":"#1e652e"},"down":{"fill":"#ef5452","stroke":"#a82529"},"neutral":{"fill":"#b5b5b5","stroke":"#575757"},"altUp":{"fill":"#5090dc","stroke":"#2b5c95"},"altDown":{"fill":"#ffa03a","stroke":"#cc6f10"},"altNeutral":{"fill":"#b5b5b5","stroke":"#575757"}},"cellRange":{"rowStartIndex":null,"rowStartPinned":null,"rowEndIndex":null,"rowEndPinned":null,"columns":[]},"switchCategorySeries":false,"suppressChartRanges":false,"unlinkChart":false,"version":"32.2.2"},"rangeChartModel":{"rangeColumns":[],"switchCategorySeries":false}}},"6":{"height":38,"type":"stream"},"7":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"0cf68a9e-328f-4cd7-8e9e-6b4f3b165389","nodeType":"const"}},"chartState":{"chartModel":{"modelType":"range","chartId":"id-s5gyid0hrm9","chartType":"groupedColumn","chartThemeName":"datalabTheme","chartOptions":{"common":{"animation":{"enabled":true}}},"chartPalette":{"fills":["#6568A0","#43D7A4","#4095DB","#FACC5F","#CAE279","#F08083","#5BCDF2","#F099DC","#965858","#7DB64F","#A98954"],"strokes":["#6568A0","#43D7A4","#4095DB","#FACC5F","#CAE279","#F08083","#5BCDF2","#F099DC","#965858","#7DB64F","#A98954"],"up":{"fill":"#459d55","stroke":"#1e652e"},"down":{"fill":"#ef5452","stroke":"#a82529"},"neutral":{"fill":"#b5b5b5","stroke":"#575757"},"altUp":{"fill":"#5090dc","stroke":"#2b5c95"},"altDown":{"fill":"#ffa03a","stroke":"#cc6f10"},"altNeutral":{"fill":"#b5b5b5","stroke":"#575757"}},"cellRange":{"rowStartIndex":null,"rowStartPinned":null,"rowEndIndex":null,"rowEndPinned":null,"columns":[]},"switchCategorySeries":false,"suppressChartRanges":false,"unlinkChart":false,"version":"32.2.2"},"rangeChartModel":{"rangeColumns":[],"switchCategorySeries":false}}},"8":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"0aa1ca12-f66a-43ac-8128-c3c45be15f25","nodeType":"const"}}},"9":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"0cf68a9e-328f-4cd7-8e9e-6b4f3b165389","nodeType":"const"}}},"10":{"height":59,"type":"stream"},"11":{"height":1,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"0cf68a9e-328f-4cd7-8e9e-6b4f3b165389","nodeType":"const"}}},"12":{"height":416,"type":"stream"},"13":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"0cf68a9e-328f-4cd7-8e9e-6b4f3b165389","nodeType":"const"}}},"14":{"height":59,"type":"stream"},"15":{"height":1,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"0cf68a9e-328f-4cd7-8e9e-6b4f3b165389","nodeType":"const"}}},"16":{"height":248,"type":"stream"},"17":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"0cf68a9e-328f-4cd7-8e9e-6b4f3b165389","nodeType":"const"}}},"18":{"height":38,"type":"stream"},"19":{"height":1,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"0cf68a9e-328f-4cd7-8e9e-6b4f3b165389","nodeType":"const"}}},"20":{"height":38,"type":"stream"},"21":{"height":1,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"0cf68a9e-328f-4cd7-8e9e-6b4f3b165389","nodeType":"const"}}},"22":{"height":38,"type":"stream"},"23":{"height":1,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"0cf68a9e-328f-4cd7-8e9e-6b4f3b165389","nodeType":"const"}}},"24":{"height":38,"type":"stream"},"25":{"height":1,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"0cf68a9e-328f-4cd7-8e9e-6b4f3b165389","nodeType":"const"}}},"26":{"height":38,"type":"stream"},"27":{"height":1,"type":"dataFrame"},"28":{"height":38,"type":"stream"},"29":{"height":1,"type":"dataFrame"},"30":{"height":38,"type":"stream"},"31":{"height":1,"type":"dataFrame"},"32":{"height":38,"type":"stream"},"33":{"height":1,"type":"dataFrame"},"34":{"height":38,"type":"stream"},"35":{"height":1,"type":"dataFrame"},"36":{"height":38,"type":"stream"},"37":{"height":1,"type":"dataFrame"},"38":{"height":38,"type":"stream"},"39":{"height":1,"type":"dataFrame"},"40":{"height":38,"type":"stream"},"41":{"height":1,"type":"dataFrame"},"42":{"height":38,"type":"stream"},"43":{"height":1,"type":"dataFrame"},"44":{"height":38,"type":"stream"},"45":{"height":1,"type":"dataFrame"},"46":{"height":38,"type":"stream"},"47":{"height":1,"type":"dataFrame"},"48":{"height":38,"type":"stream"},"49":{"height":1,"type":"dataFrame"},"50":{"height":38,"type":"stream"},"51":{"height":1,"type":"dataFrame"},"52":{"height":38,"type":"stream"},"53":{"height":1,"type":"dataFrame"},"54":{"height":38,"type":"stream"},"55":{"height":1,"type":"dataFrame"},"56":{"height":38,"type":"stream"},"57":{"height":1,"type":"dataFrame"},"58":{"height":38,"type":"stream"},"59":{"height":1,"type":"dataFrame"},"60":{"height":38,"type":"stream"},"61":{"height":1,"type":"dataFrame"},"62":{"height":38,"type":"stream"},"63":{"height":1,"type":"dataFrame"},"64":{"height":38,"type":"stream"},"65":{"height":1,"type":"dataFrame"},"66":{"height":38,"type":"stream"},"67":{"height":1,"type":"dataFrame"},"68":{"height":38,"type":"stream"},"69":{"height":1,"type":"dataFrame"},"70":{"height":38,"type":"stream"},"71":{"height":1,"type":"dataFrame"},"72":{"height":38,"type":"stream"},"73":{"height":1,"type":"dataFrame"},"74":{"height":38,"type":"stream"},"75":{"height":1,"type":"dataFrame"},"76":{"height":38,"type":"stream"},"77":{"height":1,"type":"dataFrame"},"78":{"height":38,"type":"stream"},"79":{"height":1,"type":"dataFrame"},"80":{"height":38,"type":"stream"},"81":{"height":1,"type":"dataFrame"},"82":{"height":38,"type":"stream"},"83":{"height":1,"type":"dataFrame"},"84":{"height":38,"type":"stream"},"85":{"height":1,"type":"dataFrame"},"86":{"height":38,"type":"stream"},"87":{"height":1,"type":"dataFrame"},"88":{"height":38,"type":"stream"}},"visualizeDataframe":false,"version":"ag-charts-v1"},"id":"d0eb4f16-5a99-460d-a5ba-706b7ef0bbe7","cell_type":"code","execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":"Logisitic Regression\n\n Best Feature: driving_experience (Accuracy: 0.7608)\n\n Summary of All Features:\n\n"},{"output_type":"display_data","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"Feature","type":"string"},{"name":"Accuracy","type":"number"},{"name":"Precision","type":"number"},{"name":"Recall","type":"number"},{"name":"F1","type":"number"},{"name":"Predicted_Classes","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[2,0,15,6,8,13,5,7,9,4,3,14,11,1,10,12],"Feature":["driving_experience","age","past_accidents","vehicle_ownership","married","speeding_violations","credit_score","vehicle_year","children","income","education","duis","annual_mileage","gender","postal_code","vehicle_type"],"Accuracy":[0.7607655502,0.7105263158,0.7025518341,0.6818181818,0.6642743222,0.6515151515,0.6355661882,0.6339712919,0.6331738437,0.625199362,0.5725677831,0.5677830941,0.5645933014,0.5566188198,0.4792663477,0.4792663477],"Precision":[0.7673179396,0.6608108108,0.6454081633,0.7186147186,0.6311953353,0.5931818182,0.625,0.5734989648,0.6651053864,0.6135181976,0.5401730532,0.5280685062,0.5310033822,0.5341426404,0.4792663477,0.4792663477],"Recall":[0.7188019967,0.8136439268,0.8419301165,0.5524126456,0.7204658902,0.8685524126,0.5990016639,0.921797005,0.4725457571,0.5890183028,0.7271214642,0.9234608985,0.7836938436,0.5856905158,1,1],"F1":[0.7422680412,0.7293064877,0.7306859206,0.6246472248,0.6728826729,0.704929102,0.6117247239,0.7070835992,0.5525291829,0.6010186757,0.619858156,0.6719128329,0.6330645161,0.5587301587,0.6479784367,0.6479784367],"Predicted_Classes":[{"0.0":691,"1.0":563},{"0.0":514,"1.0":740},{"0.0":470,"1.0":784},{"0.0":792,"1.0":462},{"0.0":568,"1.0":686},{"0.0":374,"1.0":880},{"0.0":678,"1.0":576},{"0.0":288,"1.0":966},{"0.0":827,"1.0":427},{"0.0":677,"1.0":577},{"0.0":445,"1.0":809},{"0.0":203,"1.0":1051},{"0.0":367,"1.0":887},{"0.0":595,"1.0":659},{"1.0":1254},{"1.0":1254}]}},"total_rows":16,"truncation_type":null},"text/plain":"                Feature  Accuracy  ...        F1      Predicted_Classes\n2    driving_experience  0.760766  ...  0.742268   {0.0: 691, 1.0: 563}\n0                   age  0.710526  ...  0.729306   {0.0: 514, 1.0: 740}\n15       past_accidents  0.702552  ...  0.730686   {0.0: 470, 1.0: 784}\n6     vehicle_ownership  0.681818  ...  0.624647   {0.0: 792, 1.0: 462}\n8               married  0.664274  ...  0.672883   {0.0: 568, 1.0: 686}\n13  speeding_violations  0.651515  ...  0.704929   {0.0: 374, 1.0: 880}\n5          credit_score  0.635566  ...  0.611725   {0.0: 678, 1.0: 576}\n7          vehicle_year  0.633971  ...  0.707084   {0.0: 288, 1.0: 966}\n9              children  0.633174  ...  0.552529   {0.0: 827, 1.0: 427}\n4                income  0.625199  ...  0.601019   {0.0: 677, 1.0: 577}\n3             education  0.572568  ...  0.619858   {0.0: 445, 1.0: 809}\n14                 duis  0.567783  ...  0.671913  {0.0: 203, 1.0: 1051}\n11       annual_mileage  0.564593  ...  0.633065   {0.0: 367, 1.0: 887}\n1                gender  0.556619  ...  0.558730   {0.0: 595, 1.0: 659}\n10          postal_code  0.479266  ...  0.647978            {1.0: 1254}\n12         vehicle_type  0.479266  ...  0.647978            {1.0: 1254}\n\n[16 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Predicted_Classes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>driving_experience</td>\n      <td>0.760766</td>\n      <td>0.767318</td>\n      <td>0.718802</td>\n      <td>0.742268</td>\n      <td>{0.0: 691, 1.0: 563}</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>age</td>\n      <td>0.710526</td>\n      <td>0.660811</td>\n      <td>0.813644</td>\n      <td>0.729306</td>\n      <td>{0.0: 514, 1.0: 740}</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>past_accidents</td>\n      <td>0.702552</td>\n      <td>0.645408</td>\n      <td>0.841930</td>\n      <td>0.730686</td>\n      <td>{0.0: 470, 1.0: 784}</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>vehicle_ownership</td>\n      <td>0.681818</td>\n      <td>0.718615</td>\n      <td>0.552413</td>\n      <td>0.624647</td>\n      <td>{0.0: 792, 1.0: 462}</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>married</td>\n      <td>0.664274</td>\n      <td>0.631195</td>\n      <td>0.720466</td>\n      <td>0.672883</td>\n      <td>{0.0: 568, 1.0: 686}</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>speeding_violations</td>\n      <td>0.651515</td>\n      <td>0.593182</td>\n      <td>0.868552</td>\n      <td>0.704929</td>\n      <td>{0.0: 374, 1.0: 880}</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>credit_score</td>\n      <td>0.635566</td>\n      <td>0.625000</td>\n      <td>0.599002</td>\n      <td>0.611725</td>\n      <td>{0.0: 678, 1.0: 576}</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>vehicle_year</td>\n      <td>0.633971</td>\n      <td>0.573499</td>\n      <td>0.921797</td>\n      <td>0.707084</td>\n      <td>{0.0: 288, 1.0: 966}</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>children</td>\n      <td>0.633174</td>\n      <td>0.665105</td>\n      <td>0.472546</td>\n      <td>0.552529</td>\n      <td>{0.0: 827, 1.0: 427}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>income</td>\n      <td>0.625199</td>\n      <td>0.613518</td>\n      <td>0.589018</td>\n      <td>0.601019</td>\n      <td>{0.0: 677, 1.0: 577}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>education</td>\n      <td>0.572568</td>\n      <td>0.540173</td>\n      <td>0.727121</td>\n      <td>0.619858</td>\n      <td>{0.0: 445, 1.0: 809}</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>duis</td>\n      <td>0.567783</td>\n      <td>0.528069</td>\n      <td>0.923461</td>\n      <td>0.671913</td>\n      <td>{0.0: 203, 1.0: 1051}</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>annual_mileage</td>\n      <td>0.564593</td>\n      <td>0.531003</td>\n      <td>0.783694</td>\n      <td>0.633065</td>\n      <td>{0.0: 367, 1.0: 887}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gender</td>\n      <td>0.556619</td>\n      <td>0.534143</td>\n      <td>0.585691</td>\n      <td>0.558730</td>\n      <td>{0.0: 595, 1.0: 659}</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>postal_code</td>\n      <td>0.479266</td>\n      <td>0.479266</td>\n      <td>1.000000</td>\n      <td>0.647978</td>\n      <td>{1.0: 1254}</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>vehicle_type</td>\n      <td>0.479266</td>\n      <td>0.479266</td>\n      <td>1.000000</td>\n      <td>0.647978</td>\n      <td>{1.0: 1254}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}}},{"output_type":"stream","name":"stdout","text":"Decision Tree Classifier\n\n Best Feature: driving_experience (Accuracy: 0.7568)\n\n Summary of All Features:\n\n"},{"output_type":"display_data","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"Feature","type":"string"},{"name":"Accuracy","type":"number"},{"name":"Precision","type":"number"},{"name":"Recall","type":"number"},{"name":"F1","type":"number"},{"name":"Predicted_Classes","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[2,0,15,13,4,6,8,7,5,9,10,3,14,11,1,12],"Feature":["driving_experience","age","past_accidents","speeding_violations","income","vehicle_ownership","married","vehicle_year","credit_score","children","postal_code","education","duis","annual_mileage","gender","vehicle_type"],"Accuracy":[0.7567783094,0.7049441786,0.7001594896,0.6985645933,0.6929824561,0.6706539075,0.6475279107,0.6403508772,0.6156299841,0.6116427432,0.5925039872,0.5717703349,0.5701754386,0.5693779904,0.5645933014,0.4792663477],"Precision":[0.7605633803,0.6546184739,0.6429479034,0.6496644295,0.6963636364,0.6974789916,0.612446959,0.5782881002,0.5825242718,0.6255506608,0.6086956522,0.5395061728,0.5295801527,0.5519591141,0.5423728814,0.4792663477],"Recall":[0.7188019967,0.8136439268,0.8419301165,0.8053244592,0.6372712146,0.5524126456,0.7204658902,0.921797005,0.6988352745,0.4725457571,0.4193011647,0.7271214642,0.9234608985,0.5391014975,0.5856905158,1],"F1":[0.7390932421,0.7255192878,0.7291066282,0.7191679049,0.6655082537,0.6165273909,0.6620795107,0.7107119949,0.6354009077,0.5383886256,0.4965517241,0.6194188519,0.6731352335,0.5454545455,0.5632,0.6479784367],"Predicted_Classes":[{"0.0":686,"1.0":568},{"0.0":507,"1.0":747},{"0.0":467,"1.0":787},{"0.0":509,"1.0":745},{"0.0":704,"1.0":550},{"0.0":778,"1.0":476},{"0.0":547,"1.0":707},{"0.0":296,"1.0":958},{"0.0":533,"1.0":721},{"0.0":800,"1.0":454},{"0.0":840,"1.0":414},{"0.0":444,"1.0":810},{"0.0":206,"1.0":1048},{"0.0":667,"1.0":587},{"0.0":605,"1.0":649},{"1.0":1254}]}},"total_rows":16,"truncation_type":null},"text/plain":"                Feature  Accuracy  ...        F1      Predicted_Classes\n2    driving_experience  0.756778  ...  0.739093   {0.0: 686, 1.0: 568}\n0                   age  0.704944  ...  0.725519   {0.0: 507, 1.0: 747}\n15       past_accidents  0.700159  ...  0.729107   {0.0: 467, 1.0: 787}\n13  speeding_violations  0.698565  ...  0.719168   {0.0: 509, 1.0: 745}\n4                income  0.692982  ...  0.665508   {0.0: 704, 1.0: 550}\n6     vehicle_ownership  0.670654  ...  0.616527   {0.0: 778, 1.0: 476}\n8               married  0.647528  ...  0.662080   {0.0: 547, 1.0: 707}\n7          vehicle_year  0.640351  ...  0.710712   {0.0: 296, 1.0: 958}\n5          credit_score  0.615630  ...  0.635401   {0.0: 533, 1.0: 721}\n9              children  0.611643  ...  0.538389   {0.0: 800, 1.0: 454}\n10          postal_code  0.592504  ...  0.496552   {0.0: 840, 1.0: 414}\n3             education  0.571770  ...  0.619419   {0.0: 444, 1.0: 810}\n14                 duis  0.570175  ...  0.673135  {0.0: 206, 1.0: 1048}\n11       annual_mileage  0.569378  ...  0.545455   {0.0: 667, 1.0: 587}\n1                gender  0.564593  ...  0.563200   {0.0: 605, 1.0: 649}\n12         vehicle_type  0.479266  ...  0.647978            {1.0: 1254}\n\n[16 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Predicted_Classes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>driving_experience</td>\n      <td>0.756778</td>\n      <td>0.760563</td>\n      <td>0.718802</td>\n      <td>0.739093</td>\n      <td>{0.0: 686, 1.0: 568}</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>age</td>\n      <td>0.704944</td>\n      <td>0.654618</td>\n      <td>0.813644</td>\n      <td>0.725519</td>\n      <td>{0.0: 507, 1.0: 747}</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>past_accidents</td>\n      <td>0.700159</td>\n      <td>0.642948</td>\n      <td>0.841930</td>\n      <td>0.729107</td>\n      <td>{0.0: 467, 1.0: 787}</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>speeding_violations</td>\n      <td>0.698565</td>\n      <td>0.649664</td>\n      <td>0.805324</td>\n      <td>0.719168</td>\n      <td>{0.0: 509, 1.0: 745}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>income</td>\n      <td>0.692982</td>\n      <td>0.696364</td>\n      <td>0.637271</td>\n      <td>0.665508</td>\n      <td>{0.0: 704, 1.0: 550}</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>vehicle_ownership</td>\n      <td>0.670654</td>\n      <td>0.697479</td>\n      <td>0.552413</td>\n      <td>0.616527</td>\n      <td>{0.0: 778, 1.0: 476}</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>married</td>\n      <td>0.647528</td>\n      <td>0.612447</td>\n      <td>0.720466</td>\n      <td>0.662080</td>\n      <td>{0.0: 547, 1.0: 707}</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>vehicle_year</td>\n      <td>0.640351</td>\n      <td>0.578288</td>\n      <td>0.921797</td>\n      <td>0.710712</td>\n      <td>{0.0: 296, 1.0: 958}</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>credit_score</td>\n      <td>0.615630</td>\n      <td>0.582524</td>\n      <td>0.698835</td>\n      <td>0.635401</td>\n      <td>{0.0: 533, 1.0: 721}</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>children</td>\n      <td>0.611643</td>\n      <td>0.625551</td>\n      <td>0.472546</td>\n      <td>0.538389</td>\n      <td>{0.0: 800, 1.0: 454}</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>postal_code</td>\n      <td>0.592504</td>\n      <td>0.608696</td>\n      <td>0.419301</td>\n      <td>0.496552</td>\n      <td>{0.0: 840, 1.0: 414}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>education</td>\n      <td>0.571770</td>\n      <td>0.539506</td>\n      <td>0.727121</td>\n      <td>0.619419</td>\n      <td>{0.0: 444, 1.0: 810}</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>duis</td>\n      <td>0.570175</td>\n      <td>0.529580</td>\n      <td>0.923461</td>\n      <td>0.673135</td>\n      <td>{0.0: 206, 1.0: 1048}</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>annual_mileage</td>\n      <td>0.569378</td>\n      <td>0.551959</td>\n      <td>0.539101</td>\n      <td>0.545455</td>\n      <td>{0.0: 667, 1.0: 587}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gender</td>\n      <td>0.564593</td>\n      <td>0.542373</td>\n      <td>0.585691</td>\n      <td>0.563200</td>\n      <td>{0.0: 605, 1.0: 649}</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>vehicle_type</td>\n      <td>0.479266</td>\n      <td>0.479266</td>\n      <td>1.000000</td>\n      <td>0.647978</td>\n      <td>{1.0: 1254}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}}},{"output_type":"stream","name":"stdout","text":"Random Forest Classifier\n\n Best Feature: driving_experience (Accuracy: 0.7711)\n\n Summary of All Features:\n\n"},{"output_type":"display_data","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"Feature","type":"string"},{"name":"Accuracy","type":"number"},{"name":"Precision","type":"number"},{"name":"Recall","type":"number"},{"name":"F1","type":"number"},{"name":"Predicted_Classes","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[2,0,4,13,15,6,8,7,9,10,3,11,14,1,5,12],"Feature":["driving_experience","age","income","speeding_violations","past_accidents","vehicle_ownership","married","vehicle_year","children","postal_code","education","annual_mileage","duis","gender","credit_score","vehicle_type"],"Accuracy":[0.7711323764,0.7352472089,0.7264752791,0.7089314195,0.706539075,0.687400319,0.6499202552,0.6363636364,0.620414673,0.5757575758,0.5741626794,0.5717703349,0.5709728868,0.5685805423,0.54784689,0.4792663477],"Precision":[0.7854545455,0.6897038082,0.7539370079,0.6612021858,0.649550706,0.7296703297,0.6150568182,0.5752855659,0.6410835214,0.5793103448,0.541511772,0.5547945205,0.5300859599,0.5465838509,0.5237430168,0.4792663477],"Recall":[0.7188019967,0.8136439268,0.6372712146,0.8053244592,0.8419301165,0.5524126456,0.7204658902,0.921797005,0.4725457571,0.4193011647,0.7271214642,0.5391014975,0.9234608985,0.5856905158,0.6239600666,1],"F1":[0.7506516073,0.7465648855,0.6907123535,0.7261815454,0.7333333333,0.6287878788,0.6636015326,0.7084398977,0.5440613027,0.4864864865,0.6207386364,0.546835443,0.6735436893,0.5654618474,0.569476082,0.6479784367],"Predicted_Classes":[{"0.0":704,"1.0":550},{"0.0":545,"1.0":709},{"0.0":746,"1.0":508},{"0.0":522,"1.0":732},{"0.0":475,"1.0":779},{"0.0":799,"1.0":455},{"0.0":550,"1.0":704},{"0.0":291,"1.0":963},{"0.0":811,"1.0":443},{"0.0":819,"1.0":435},{"0.0":447,"1.0":807},{"0.0":670,"1.0":584},{"0.0":207,"1.0":1047},{"0.0":610,"1.0":644},{"0.0":538,"1.0":716},{"1.0":1254}]}},"total_rows":16,"truncation_type":null},"text/plain":"                Feature  Accuracy  ...        F1      Predicted_Classes\n2    driving_experience  0.771132  ...  0.750652   {0.0: 704, 1.0: 550}\n0                   age  0.735247  ...  0.746565   {0.0: 545, 1.0: 709}\n4                income  0.726475  ...  0.690712   {0.0: 746, 1.0: 508}\n13  speeding_violations  0.708931  ...  0.726182   {0.0: 522, 1.0: 732}\n15       past_accidents  0.706539  ...  0.733333   {0.0: 475, 1.0: 779}\n6     vehicle_ownership  0.687400  ...  0.628788   {0.0: 799, 1.0: 455}\n8               married  0.649920  ...  0.663602   {0.0: 550, 1.0: 704}\n7          vehicle_year  0.636364  ...  0.708440   {0.0: 291, 1.0: 963}\n9              children  0.620415  ...  0.544061   {0.0: 811, 1.0: 443}\n10          postal_code  0.575758  ...  0.486486   {0.0: 819, 1.0: 435}\n3             education  0.574163  ...  0.620739   {0.0: 447, 1.0: 807}\n11       annual_mileage  0.571770  ...  0.546835   {0.0: 670, 1.0: 584}\n14                 duis  0.570973  ...  0.673544  {0.0: 207, 1.0: 1047}\n1                gender  0.568581  ...  0.565462   {0.0: 610, 1.0: 644}\n5          credit_score  0.547847  ...  0.569476   {0.0: 538, 1.0: 716}\n12         vehicle_type  0.479266  ...  0.647978            {1.0: 1254}\n\n[16 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Predicted_Classes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>driving_experience</td>\n      <td>0.771132</td>\n      <td>0.785455</td>\n      <td>0.718802</td>\n      <td>0.750652</td>\n      <td>{0.0: 704, 1.0: 550}</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>age</td>\n      <td>0.735247</td>\n      <td>0.689704</td>\n      <td>0.813644</td>\n      <td>0.746565</td>\n      <td>{0.0: 545, 1.0: 709}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>income</td>\n      <td>0.726475</td>\n      <td>0.753937</td>\n      <td>0.637271</td>\n      <td>0.690712</td>\n      <td>{0.0: 746, 1.0: 508}</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>speeding_violations</td>\n      <td>0.708931</td>\n      <td>0.661202</td>\n      <td>0.805324</td>\n      <td>0.726182</td>\n      <td>{0.0: 522, 1.0: 732}</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>past_accidents</td>\n      <td>0.706539</td>\n      <td>0.649551</td>\n      <td>0.841930</td>\n      <td>0.733333</td>\n      <td>{0.0: 475, 1.0: 779}</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>vehicle_ownership</td>\n      <td>0.687400</td>\n      <td>0.729670</td>\n      <td>0.552413</td>\n      <td>0.628788</td>\n      <td>{0.0: 799, 1.0: 455}</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>married</td>\n      <td>0.649920</td>\n      <td>0.615057</td>\n      <td>0.720466</td>\n      <td>0.663602</td>\n      <td>{0.0: 550, 1.0: 704}</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>vehicle_year</td>\n      <td>0.636364</td>\n      <td>0.575286</td>\n      <td>0.921797</td>\n      <td>0.708440</td>\n      <td>{0.0: 291, 1.0: 963}</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>children</td>\n      <td>0.620415</td>\n      <td>0.641084</td>\n      <td>0.472546</td>\n      <td>0.544061</td>\n      <td>{0.0: 811, 1.0: 443}</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>postal_code</td>\n      <td>0.575758</td>\n      <td>0.579310</td>\n      <td>0.419301</td>\n      <td>0.486486</td>\n      <td>{0.0: 819, 1.0: 435}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>education</td>\n      <td>0.574163</td>\n      <td>0.541512</td>\n      <td>0.727121</td>\n      <td>0.620739</td>\n      <td>{0.0: 447, 1.0: 807}</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>annual_mileage</td>\n      <td>0.571770</td>\n      <td>0.554795</td>\n      <td>0.539101</td>\n      <td>0.546835</td>\n      <td>{0.0: 670, 1.0: 584}</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>duis</td>\n      <td>0.570973</td>\n      <td>0.530086</td>\n      <td>0.923461</td>\n      <td>0.673544</td>\n      <td>{0.0: 207, 1.0: 1047}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gender</td>\n      <td>0.568581</td>\n      <td>0.546584</td>\n      <td>0.585691</td>\n      <td>0.565462</td>\n      <td>{0.0: 610, 1.0: 644}</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>credit_score</td>\n      <td>0.547847</td>\n      <td>0.523743</td>\n      <td>0.623960</td>\n      <td>0.569476</td>\n      <td>{0.0: 538, 1.0: 716}</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>vehicle_type</td>\n      <td>0.479266</td>\n      <td>0.479266</td>\n      <td>1.000000</td>\n      <td>0.647978</td>\n      <td>{1.0: 1254}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}}},{"output_type":"stream","name":"stdout","text":"Standard Vector Machine Classifier\n\n Best Feature: driving_experience (Accuracy: 0.7679)\n\n Summary of All Features:\n\n"},{"output_type":"display_data","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"Feature","type":"string"},{"name":"Accuracy","type":"number"},{"name":"Precision","type":"number"},{"name":"Recall","type":"number"},{"name":"F1","type":"number"},{"name":"Predicted_Classes","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[2,0,15,6,5,13,7,4,8,9,1,3,14,11,10,12],"Feature":["driving_experience","age","past_accidents","vehicle_ownership","credit_score","speeding_violations","vehicle_year","income","married","children","gender","education","duis","annual_mileage","postal_code","vehicle_type"],"Accuracy":[0.7679425837,0.706539075,0.706539075,0.7001594896,0.6507177033,0.6499202552,0.6403508772,0.6379585327,0.6355661882,0.6315789474,0.5717703349,0.5661881978,0.5661881978,0.5534290271,0.5279106858,0.4792663477],"Precision":[0.7797833935,0.6563758389,0.649550706,0.7562642369,0.6489945155,0.5918367347,0.5782881002,0.6310160428,0.5997229917,0.662004662,0.55,0.5348837209,0.5270655271,0.5330112721,0.5652173913,0.4792663477],"Recall":[0.7188019967,0.8136439268,0.8419301165,0.5524126456,0.5906821963,0.8685524126,0.921797005,0.5890183028,0.7204658902,0.4725457571,0.5856905158,0.7271214642,0.9234608985,0.5507487521,0.0648918469,1],"F1":[0.7480519481,0.7265973254,0.7333333333,0.6384615385,0.618466899,0.7039784221,0.7107119949,0.6092943201,0.6545729403,0.5514563107,0.567284448,0.6163610719,0.6711003628,0.5417348609,0.1164179104,0.6479784367],"Predicted_Classes":[{"0.0":700,"1.0":554},{"0.0":509,"1.0":745},{"0.0":475,"1.0":779},{"0.0":815,"1.0":439},{"0.0":707,"1.0":547},{"0.0":372,"1.0":882},{"0.0":296,"1.0":958},{"0.0":693,"1.0":561},{"0.0":532,"1.0":722},{"0.0":825,"1.0":429},{"0.0":614,"1.0":640},{"0.0":437,"1.0":817},{"0.0":201,"1.0":1053},{"0.0":633,"1.0":621},{"0.0":1185,"1.0":69},{"1.0":1254}]}},"total_rows":16,"truncation_type":null},"text/plain":"                Feature  Accuracy  ...        F1      Predicted_Classes\n2    driving_experience  0.767943  ...  0.748052   {0.0: 700, 1.0: 554}\n0                   age  0.706539  ...  0.726597   {0.0: 509, 1.0: 745}\n15       past_accidents  0.706539  ...  0.733333   {0.0: 475, 1.0: 779}\n6     vehicle_ownership  0.700159  ...  0.638462   {0.0: 815, 1.0: 439}\n5          credit_score  0.650718  ...  0.618467   {0.0: 707, 1.0: 547}\n13  speeding_violations  0.649920  ...  0.703978   {0.0: 372, 1.0: 882}\n7          vehicle_year  0.640351  ...  0.710712   {0.0: 296, 1.0: 958}\n4                income  0.637959  ...  0.609294   {0.0: 693, 1.0: 561}\n8               married  0.635566  ...  0.654573   {0.0: 532, 1.0: 722}\n9              children  0.631579  ...  0.551456   {0.0: 825, 1.0: 429}\n1                gender  0.571770  ...  0.567284   {0.0: 614, 1.0: 640}\n3             education  0.566188  ...  0.616361   {0.0: 437, 1.0: 817}\n14                 duis  0.566188  ...  0.671100  {0.0: 201, 1.0: 1053}\n11       annual_mileage  0.553429  ...  0.541735   {0.0: 633, 1.0: 621}\n10          postal_code  0.527911  ...  0.116418   {0.0: 1185, 1.0: 69}\n12         vehicle_type  0.479266  ...  0.647978            {1.0: 1254}\n\n[16 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Predicted_Classes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>driving_experience</td>\n      <td>0.767943</td>\n      <td>0.779783</td>\n      <td>0.718802</td>\n      <td>0.748052</td>\n      <td>{0.0: 700, 1.0: 554}</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>age</td>\n      <td>0.706539</td>\n      <td>0.656376</td>\n      <td>0.813644</td>\n      <td>0.726597</td>\n      <td>{0.0: 509, 1.0: 745}</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>past_accidents</td>\n      <td>0.706539</td>\n      <td>0.649551</td>\n      <td>0.841930</td>\n      <td>0.733333</td>\n      <td>{0.0: 475, 1.0: 779}</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>vehicle_ownership</td>\n      <td>0.700159</td>\n      <td>0.756264</td>\n      <td>0.552413</td>\n      <td>0.638462</td>\n      <td>{0.0: 815, 1.0: 439}</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>credit_score</td>\n      <td>0.650718</td>\n      <td>0.648995</td>\n      <td>0.590682</td>\n      <td>0.618467</td>\n      <td>{0.0: 707, 1.0: 547}</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>speeding_violations</td>\n      <td>0.649920</td>\n      <td>0.591837</td>\n      <td>0.868552</td>\n      <td>0.703978</td>\n      <td>{0.0: 372, 1.0: 882}</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>vehicle_year</td>\n      <td>0.640351</td>\n      <td>0.578288</td>\n      <td>0.921797</td>\n      <td>0.710712</td>\n      <td>{0.0: 296, 1.0: 958}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>income</td>\n      <td>0.637959</td>\n      <td>0.631016</td>\n      <td>0.589018</td>\n      <td>0.609294</td>\n      <td>{0.0: 693, 1.0: 561}</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>married</td>\n      <td>0.635566</td>\n      <td>0.599723</td>\n      <td>0.720466</td>\n      <td>0.654573</td>\n      <td>{0.0: 532, 1.0: 722}</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>children</td>\n      <td>0.631579</td>\n      <td>0.662005</td>\n      <td>0.472546</td>\n      <td>0.551456</td>\n      <td>{0.0: 825, 1.0: 429}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gender</td>\n      <td>0.571770</td>\n      <td>0.550000</td>\n      <td>0.585691</td>\n      <td>0.567284</td>\n      <td>{0.0: 614, 1.0: 640}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>education</td>\n      <td>0.566188</td>\n      <td>0.534884</td>\n      <td>0.727121</td>\n      <td>0.616361</td>\n      <td>{0.0: 437, 1.0: 817}</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>duis</td>\n      <td>0.566188</td>\n      <td>0.527066</td>\n      <td>0.923461</td>\n      <td>0.671100</td>\n      <td>{0.0: 201, 1.0: 1053}</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>annual_mileage</td>\n      <td>0.553429</td>\n      <td>0.533011</td>\n      <td>0.550749</td>\n      <td>0.541735</td>\n      <td>{0.0: 633, 1.0: 621}</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>postal_code</td>\n      <td>0.527911</td>\n      <td>0.565217</td>\n      <td>0.064892</td>\n      <td>0.116418</td>\n      <td>{0.0: 1185, 1.0: 69}</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>vehicle_type</td>\n      <td>0.479266</td>\n      <td>0.479266</td>\n      <td>1.000000</td>\n      <td>0.647978</td>\n      <td>{1.0: 1254}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}}}]}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}